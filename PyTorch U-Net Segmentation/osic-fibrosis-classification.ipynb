{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":20604,"databundleVersionId":1357052,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AI-Driven Early Prediction of Pulmonary Fibrosis Using Deep Learning\n## Classification","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport pydicom\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom tqdm.notebook import tqdm\nfrom skimage import measure, morphology\nfrom pathlib import Path\nimport json\nimport time\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n# ==========================================\n# 1. CONFIGURATION & DIRECTORY SETUP\n# ==========================================\nCONFIG = {\n    \"batch_size\": 16,             # Paper suggests powers of 2 (16, 32)\n    \"epochs\": 50,                 # Maximum epochs\n    \"lr\": 2e-5,                   # Standard starting point for Adam\n    \"image_size\": 256,            \n    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n    \"root_dir\": \"../input/osic-pulmonary-fibrosis-progression/train\",\n    \"version_dir\": \"version_2\",   # âœ… NEW: Dedicated directory for this run\n}\n\n# Create Version 2 Directory Structure\nos.makedirs(CONFIG['version_dir'], exist_ok=True)\n\n\n# Define Log File Path inside version directory\nLOG_FILE = os.path.join(CONFIG['version_dir'], 'metrics_log.json')\n\n# ==========================================\n# 2. IMPROVED \"GROUND TRUTH\" GENERATION\n# ==========================================\ndef generate_robust_mask(image):\n    \"\"\"\n    Refined function to generate a tighter lung mask boundary.\n    \"\"\"\n    # 1. Standardize\n    image = image.copy()\n    mean = np.mean(image)\n    std = np.std(image)\n    image = (image - mean) / std\n    \n    middle = image[100:-100, 100:-100] \n    mean_mid = np.mean(middle)  \n    \n    # Thresholding to separate lung from chest wall\n    thresh_img = np.where(image < mean_mid, 1.0, 0.0)\n\n    # 3. Morphological Cleaning\n    eroded = morphology.erosion(thresh_img, np.ones((3,3)))\n    \n    # âœ… Reduced dilation kernel size from 8x8 to 4x4\n    dilation = morphology.dilation(eroded, np.ones((4,4))) \n\n    # 4. Label regions\n    labels = measure.label(dilation)\n    regions = measure.regionprops(labels)\n    \n    good_labels = []\n    for prop in regions:\n        B = prop.bbox\n        if B[2]-B[0] < CONFIG['image_size']*0.9 and B[3]-B[1] < CONFIG['image_size']*0.9 and prop.area > 500:\n            good_labels.append(prop.label)\n            \n    mask = np.zeros_like(dilation, dtype=np.float32)\n    for l in good_labels:\n        mask = np.where(labels == l, 1.0, mask)\n\n    # 5. Final cleanup\n    # âœ… Reduced dilation kernel size from 6x6 to 3x3\n    mask = morphology.dilation(mask, np.ones((3,3))) \n    mask = cv2.GaussianBlur(mask, (5,5), 0) \n    mask = (mask > 0.5).astype(np.float32)\n    \n    # âœ… Final erosion to actively shrink boundary\n    mask = morphology.erosion(mask, np.ones((2,2)))\n    \n    return mask\n\ndef load_scan_and_mask(path):\n    try:\n        dcm = pydicom.dcmread(path)\n        img = dcm.pixel_array.astype(np.float32)\n        \n        slope = getattr(dcm, 'RescaleSlope', 1)\n        intercept = getattr(dcm, 'RescaleIntercept', -1024)\n        img = slope * img + intercept\n        \n        img = cv2.resize(img, (CONFIG['image_size'], CONFIG['image_size'])) \n        \n        mask = generate_robust_mask(img)\n        \n        img_min, img_max = -1000, 400 \n        img = np.clip(img, img_min, img_max)\n        img = (img - img_min) / (img_max - img_min)\n        \n    except Exception as e:\n        return None, None\n        \n    return img, mask\n\n# ==========================================\n# 3. STANDARD U-NET ARCHITECTURE\n# ==========================================\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass StandardUNet(nn.Module):\n    def __init__(self, in_channels=1, out_channels=1):\n        super().__init__()\n        # Encoder\n        self.inc = DoubleConv(in_channels, 64)\n        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(64, 128))\n        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(128, 256))\n        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(256, 512))\n        self.down4 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(512, 1024))\n        \n        # Decoder\n        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n        self.conv_up1 = DoubleConv(1024, 512) \n        \n        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n        self.conv_up2 = DoubleConv(512, 256)\n        \n        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n        self.conv_up3 = DoubleConv(256, 128)\n        \n        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n        self.conv_up4 = DoubleConv(128, 64)\n        \n        self.outc = nn.Conv2d(64, out_channels, kernel_size=1) \n\n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4) \n        \n        x = self.up1(x5)\n        x = torch.cat([x, x4], dim=1) \n        x = self.conv_up1(x)\n        \n        x = self.up2(x)\n        x = torch.cat([x, x3], dim=1)\n        x = self.conv_up2(x)\n        \n        x = self.up3(x)\n        x = torch.cat([x, x2], dim=1)\n        x = self.conv_up3(x)\n        \n        x = self.up4(x)\n        x = torch.cat([x, x1], dim=1)\n        x = self.conv_up4(x)\n        \n        return torch.sigmoid(self.outc(x))\n\n# ==========================================\n# 4. DICE LOSS\n# ==========================================\nclass DiceLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, pred, target):\n        smooth = 1e-5\n        pred = pred.view(-1)\n        target = target.view(-1)\n        intersection = (pred * target).sum()\n        dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)\n        return 1 - dice\n\n# ==========================================\n# 5. TRAINING LOOP\n# ==========================================\n\n# Setup Data Loaders (Remains the same)\nall_patients = sorted([p for p in os.listdir(CONFIG['root_dir']) if os.path.isdir(os.path.join(CONFIG['root_dir'], p))])\nall_files = []\nfor p in all_patients[:50]: \n    p_path = os.path.join(CONFIG['root_dir'], p)\n    files = sorted([os.path.join(p_path, f) for f in os.listdir(p_path) if f.endswith('.dcm')])\n    idx_start = int(len(files) * 0.3)\n    idx_end = int(len(files) * 0.7)\n    all_files.extend(files[idx_start:idx_end])\n\nclass LungDataset(Dataset):\n    def __init__(self, files):\n        self.files = files\n    def __len__(self): return len(self.files)\n    def __getitem__(self, idx):\n        img, mask = load_scan_and_mask(self.files[idx])\n        if img is None: return self.__getitem__((idx+1)%len(self))\n        img = torch.tensor(img).unsqueeze(0).float()\n        mask = torch.tensor(mask).unsqueeze(0).float()\n        return img, mask\n\ntrain_files, val_files = train_test_split(all_files, test_size=0.15, random_state=42)\ntrain_loader = DataLoader(LungDataset(train_files), batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2)\nval_loader = DataLoader(LungDataset(val_files), batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2)\n\n\n# ðŸŽ¯ NEW LR FOR FINE-TUNING\n# We assume CONFIG['lr'] is set to 2e-5 before this block is executed\nNEW_FINE_TUNING_LR = CONFIG['lr'] \n\n# Initialize model\nmodel = StandardUNet().to(CONFIG['device'])\n\n# âœ… Tracking variables initialization\nBEST_VAL_DICE = -1.0\nhistory = [] \n\n# --- DYNAMIC LOADING LOGIC ---\nif os.path.exists(LOG_FILE):\n    with open(LOG_FILE, 'r') as f:\n        history = json.load(f)\n        \n    if history:\n        # Find the Absolute Best Checkpoint Path based on F1 Score\n        best_entry = max(\n            (item for item in history if item.get('checkpoint_path')), \n            key=lambda x: x['val_f1_score'], \n            default=None\n        )\n        \n        if best_entry:\n            BEST_MODEL_PATH = best_entry['checkpoint_path']\n            BEST_VAL_DICE = best_entry['val_f1_score']\n\n            if os.path.exists(BEST_MODEL_PATH):\n                try:\n                    state_dict = torch.load(BEST_MODEL_PATH, map_location=CONFIG['device'])\n                    model.load_state_dict(state_dict)\n                    print(f\"âœ… Successfully loaded best weights (F1: {BEST_VAL_DICE:.4f}) from {BEST_MODEL_PATH}.\")\n                except Exception as e:\n                    print(f\"âš ï¸ Warning: Error loading best weights ({BEST_MODEL_PATH}): {e}. Starting fresh.\")\n            else:\n                 print(f\"âš ï¸ Warning: Best checkpoint path found in log but file is missing. Starting fresh.\")\n        \n# --- OPTIMIZER INITIALIZATION ---\n# Use the low LR for fine-tuning the loaded model\noptimizer = optim.Adam(model.parameters(), lr=NEW_FINE_TUNING_LR) \ncriterion = DiceLoss()\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)\n\nprint(f\"ðŸš€ Starting FINE-TUNING Run... LR: {NEW_FINE_TUNING_LR:.2e}\")\n\n\nfor epoch in range(CONFIG['epochs']):\n    model.train()\n    train_loss = 0\n    for img, mask in tqdm(train_loader, leave=False):\n        img, mask = img.to(CONFIG['device']), mask.to(CONFIG['device'])\n        optimizer.zero_grad()\n        pred = model(img)\n        loss = criterion(pred, mask)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        \n    # Validation\n    model.eval()\n    val_acc_list, val_prec_list, val_rec_list, val_f1_list, val_dice_list = [], [], [], [], []\n\n    with torch.no_grad():\n        for img, mask in val_loader:\n            img, mask = img.to(CONFIG['device']), mask.to(CONFIG['device'])\n            pred = model(img)\n            \n            # Dice (Loss Metric)\n            val_dice_list.append(1 - criterion(pred, mask).item())\n            \n            # Sklearn Metrics (Threshold 0.5)\n            pred_bin = (pred > 0.5).float().cpu().numpy().astype(int).flatten()\n            mask_np = mask.cpu().numpy().astype(int).flatten()\n            \n            val_acc_list.append(accuracy_score(mask_np, pred_bin))\n            val_prec_list.append(precision_score(mask_np, pred_bin, zero_division=1))\n            val_rec_list.append(recall_score(mask_np, pred_bin, zero_division=1))\n            val_f1_list.append(f1_score(mask_np, pred_bin, zero_division=1))\n            \n    # Aggregate\n    avg_dice = np.mean(val_dice_list)\n    avg_acc = np.mean(val_acc_list)\n    avg_prec = np.mean(val_prec_list)\n    avg_rec = np.mean(val_rec_list)\n    avg_f1 = np.mean(val_f1_list)\n    \n    current_lr = optimizer.param_groups[0]['lr']\n    scheduler.step(avg_dice)\n    \n    # âœ… DYNAMIC PATH CONSTRUCTION\n    dynamic_filename = f\"epoch_{epoch + 1}_f1_{avg_f1:.4f}.pth\"\n    dynamic_path = os.path.join(CONFIG['version_dir'], dynamic_filename)\n    \n    epoch_metrics = {\n        'epoch': epoch + 1,\n        'timestamp': time.time(),\n        'learning_rate': current_lr,\n        'train_loss': train_loss / len(train_loader),\n        'val_accuracy': avg_acc,\n        'val_precision': avg_prec,\n        'val_recall': avg_rec,\n        'val_f1_score': avg_f1,\n        'val_dice_score': avg_dice,\n        'checkpoint_path': '' \n    }\n    \n    # âœ… SAVE LOGIC: Save if it beats the best record\n    if avg_f1 > BEST_VAL_DICE:\n        BEST_VAL_DICE = avg_f1\n        torch.save(model.state_dict(), dynamic_path)\n        epoch_metrics['checkpoint_path'] = dynamic_path\n        print(f\"ðŸŽ‰ NEW BEST MODEL SAVED! F1: {avg_f1:.4f} -> {dynamic_path}\")\n    \n    history.append(epoch_metrics)\n    with open(LOG_FILE, 'w') as f:\n        json.dump(history, f, indent=4)\n    \n    print(f\"\\nâœ… Epoch {epoch+1} Summary:\")\n    print(f\"   Loss      : {train_loss/len(train_loader):.4f}\")\n    print(f\"   Accuracy  : {avg_acc:.4f}\")\n    print(f\"   Precision : {avg_prec:.4f}\")\n    print(f\"   Recall    : {avg_rec:.4f}\")\n    print(f\"   F1-Score  : {avg_f1:.4f}\")\n    print(\"-\" * 30)\n\n    if avg_dice > 0.96:\n        print(\"ðŸŽ‰ Target metrics achieved.\")\n        break","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-27T09:42:26.581481Z","iopub.execute_input":"2025-11-27T09:42:26.582211Z","iopub.status.idle":"2025-11-27T10:32:17.679609Z","shell.execute_reply.started":"2025-11-27T09:42:26.582175Z","shell.execute_reply":"2025-11-27T10:32:17.678221Z"}},"outputs":[{"name":"stdout","text":"âœ… Successfully loaded best weights (F1: 0.8990) from version_2/epoch_7_f1_0.8990.pth.\nðŸš€ Starting FINE-TUNING Run... LR: 2.00e-05\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"ðŸŽ‰ NEW BEST MODEL SAVED! F1: 0.8992 -> version_2/epoch_1_f1_0.8992.pth\n\nâœ… Epoch 1 Summary:\n   Loss      : 0.1133\n   Accuracy  : 0.9762\n   Precision : 0.9117\n   Recall    : 0.8913\n   F1-Score  : 0.8992\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"ðŸŽ‰ NEW BEST MODEL SAVED! F1: 0.8992 -> version_2/epoch_2_f1_0.8992.pth\n\nâœ… Epoch 2 Summary:\n   Loss      : 0.1120\n   Accuracy  : 0.9762\n   Precision : 0.9114\n   Recall    : 0.8915\n   F1-Score  : 0.8992\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"ðŸŽ‰ NEW BEST MODEL SAVED! F1: 0.8993 -> version_2/epoch_3_f1_0.8993.pth\n\nâœ… Epoch 3 Summary:\n   Loss      : 0.1132\n   Accuracy  : 0.9762\n   Precision : 0.9119\n   Recall    : 0.8913\n   F1-Score  : 0.8993\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"ðŸŽ‰ NEW BEST MODEL SAVED! F1: 0.8997 -> version_2/epoch_4_f1_0.8997.pth\n\nâœ… Epoch 4 Summary:\n   Loss      : 0.1119\n   Accuracy  : 0.9763\n   Precision : 0.9099\n   Recall    : 0.8939\n   F1-Score  : 0.8997\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nâœ… Epoch 5 Summary:\n   Loss      : 0.1128\n   Accuracy  : 0.9763\n   Precision : 0.9119\n   Recall    : 0.8919\n   F1-Score  : 0.8996\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"ðŸŽ‰ NEW BEST MODEL SAVED! F1: 0.9003 -> version_2/epoch_6_f1_0.9003.pth\n\nâœ… Epoch 6 Summary:\n   Loss      : 0.1106\n   Accuracy  : 0.9764\n   Precision : 0.9092\n   Recall    : 0.8958\n   F1-Score  : 0.9003\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nâœ… Epoch 7 Summary:\n   Loss      : 0.1115\n   Accuracy  : 0.9764\n   Precision : 0.9129\n   Recall    : 0.8920\n   F1-Score  : 0.9002\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nâœ… Epoch 8 Summary:\n   Loss      : 0.1106\n   Accuracy  : 0.9764\n   Precision : 0.9146\n   Recall    : 0.8896\n   F1-Score  : 0.8998\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"ðŸŽ‰ NEW BEST MODEL SAVED! F1: 0.9006 -> version_2/epoch_9_f1_0.9006.pth\n\nâœ… Epoch 9 Summary:\n   Loss      : 0.1097\n   Accuracy  : 0.9765\n   Precision : 0.9123\n   Recall    : 0.8934\n   F1-Score  : 0.9006\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"ðŸŽ‰ NEW BEST MODEL SAVED! F1: 0.9008 -> version_2/epoch_10_f1_0.9008.pth\n\nâœ… Epoch 10 Summary:\n   Loss      : 0.1103\n   Accuracy  : 0.9765\n   Precision : 0.9113\n   Recall    : 0.8947\n   F1-Score  : 0.9008\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"ðŸŽ‰ NEW BEST MODEL SAVED! F1: 0.9008 -> version_2/epoch_11_f1_0.9008.pth\n\nâœ… Epoch 11 Summary:\n   Loss      : 0.1139\n   Accuracy  : 0.9766\n   Precision : 0.9127\n   Recall    : 0.8934\n   F1-Score  : 0.9008\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nâœ… Epoch 12 Summary:\n   Loss      : 0.1093\n   Accuracy  : 0.9765\n   Precision : 0.9135\n   Recall    : 0.8921\n   F1-Score  : 0.9005\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"ðŸŽ‰ NEW BEST MODEL SAVED! F1: 0.9011 -> version_2/epoch_13_f1_0.9011.pth\n\nâœ… Epoch 13 Summary:\n   Loss      : 0.1101\n   Accuracy  : 0.9767\n   Precision : 0.9146\n   Recall    : 0.8921\n   F1-Score  : 0.9011\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"ðŸŽ‰ NEW BEST MODEL SAVED! F1: 0.9014 -> version_2/epoch_14_f1_0.9014.pth\n\nâœ… Epoch 14 Summary:\n   Loss      : 0.1078\n   Accuracy  : 0.9767\n   Precision : 0.9156\n   Recall    : 0.8918\n   F1-Score  : 0.9014\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"ðŸŽ‰ NEW BEST MODEL SAVED! F1: 0.9014 -> version_2/epoch_15_f1_0.9014.pth\n\nâœ… Epoch 15 Summary:\n   Loss      : 0.1084\n   Accuracy  : 0.9768\n   Precision : 0.9151\n   Recall    : 0.8923\n   F1-Score  : 0.9014\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"ðŸŽ‰ NEW BEST MODEL SAVED! F1: 0.9021 -> version_2/epoch_16_f1_0.9021.pth\n\nâœ… Epoch 16 Summary:\n   Loss      : 0.1102\n   Accuracy  : 0.9769\n   Precision : 0.9125\n   Recall    : 0.8962\n   F1-Score  : 0.9021\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/220 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/960569933.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mval_acc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0mval_prec_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_bin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m             \u001b[0mval_rec_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_bin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mval_f1_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_bin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1952\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m     \"\"\"\n\u001b[0;32m-> 1954\u001b[0;31m     p, _, _, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1955\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0msamplewise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"samples\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m     MCM = multilabel_confusion_matrix(\n\u001b[0m\u001b[1;32m   1578\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Check that we don't mix label format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mys_types\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Check that we don't mix label format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mys_types\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Check multiclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0mfirst_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_row\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36munique_values\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         ret = _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0m\u001b[1;32m    275\u001b[0m                         equal_nan=equal_nan)\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}